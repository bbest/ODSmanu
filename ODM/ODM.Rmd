---
title: Improving the IEA approach using principles of open data science
documentclass: article
#Finish list from google spreadsheet [https://docs.google.com/spreadsheets/d/1NO1_rLnXk3NYhwDPxaHtn6nEW_KFfgDYGK2qitXfSFI/edit#gid=0]
author: 
- name: Kimberly Bastille
  institute: one
- name: Sean Hardison
  institute: two
- name: Lynn DeWitt
  institute: three
- name: Jennifer Brown
  institute: four
- name: Jameal Samhouri
  institute: five
- name: Sarah Gaichas
  institute: six
- name: Sean Lucey
  institute: six
- name: Kelly Kearney
  institute: seven
- name: Ben Best
  institute: eight
- name: Scott Cross
  institute: nine
- name: Scott Large
  institute: six
- name: Ellen Spooner
  institute: ten

  
#Finish adding from the google spreadsheet [https://docs.google.com/spreadsheets/d/1NO1_rLnXk3NYhwDPxaHtn6nEW_KFfgDYGK2qitXfSFI/edit#gid=0]
institute: 
- one: Integrated Statistics, Woods Hole, MA, USA
- two: University of Virginia, Charlottesville, VA, USA
- three: NOAA Southwest Fisheries Science Center, La Jolla, CA, USA 
- four: NOAA Monterey Bay National Marine Sancturary, Monterey, CA, USA 
- five: NOAA Northwest Fisheries Science Center, Seattle, WA, USA
- six: Woods Hole Laboratory, NOAA NMFS Northeast Fisheries Science Center, Woods Hole, MA, USA
- seven: Location seven
- eight: EcoQuants, Santa Barbara, CA, USA
- nine: Location nine
- ten: Location ten
    
## Write Abstract
abstract: |
  The text of your abstract.  150 -- 250 words.

csl: estuaries-and-coasts.csl
bibliography: bibliography.bib
output:
  rmarkdown::pdf_document:
    pandoc_args:
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'

---

``` {r Directory setup, echo = FALSE }

image.dir <- './images'
```

# Introduction {#intro}
<!-- Grab text from google doc -->

As implemented so far, integrated ecosystem assessments are more often than not bespoke products that are specific to regional policy needs at varying spatial scales. While unique, these assessments are built around the unifying flow of the IEA framework outlined in @Levin2009. This process consists of a scoping step to outline management objectives, the identification of ecosystem indicators to monitor key processes, the compilation of ecosystem status reports highlighting status and trends of indicators, a risk assessment step identifying where ecosystem considerations might threaten management objectives, and finally management strategy evaluation, in which potential management actions are tested using simulation models. The elements of the IEA framework are central to its implementation, but are not prescriptive. Instead, the IEA process is malleable to the needs of stakeholders, meaning that IEAs may manifest in many different forms. 

Within these disparate applications of the IEA approach lie the unifying challenges of data acquisition, management, communication, and dissemination. Solving these challenges is not trivial, but over the past decade several examples have emerged suggesting the use of open data science tools as potential solutions [@rocchini2012; @lowndes2015; @lowndes2017]. Embracing these tools and strategies speaks to a broader philosophy of open science that has yet to catch on in the IEA community. Beyond making data publicly available, open science advocates for the “free and unfettered access to all aspects of the scientific endeavor” [@hampton2015], including methods, data and scientific products. Here we provide examples of how IEA teams have begun incorporating open data science practices into different pieces of the IEA loop to make IEAs more tenable as a flexible and effective decision-making framework [@Levin2009].

There are several entry and exit points for data, methodological, and scientific products throughout the execution of an IEA. Data entry points are formed during the exploratory phases of the IEA process, where objectives are scoped and representative indicators are developed. Exit points for data products can be found in the derived indicator data informing ecosystem status reports and risk assessments. Simulated products and model parameters, such as those resulting from MSE model runs, are also important to disseminate. Any data that leaves or enters an IEA brings with it metadata and code used to analyze, process, and visualize the data (in various stages of completion). 

Without an underlying data management protocol, the vast quantities of data and documentation required to successfully execute an IEA can be overwhelming for practitioners and clients both. For example, the development of ecosystem status reports and risk assessments requires considering the management relevance of hundreds of data sets from many fields. In practice this meant sifting through over 400 unique spatial and temporal data sets that were submitted for consideration during the development of the New England State of the Ecosystem Report, an IEA product. However, only indicators of interest to managers and those necessary for storytelling were included in the final product; just over 90 [@SOE-NEFMC2019].  Depending on the governing body implementing the IEA, each data set must be fully documented with metadata and made publicly available. Versioning data sets and associated metadata relative to specific IEA products also introduces challenges for scientists operating outside the bounds of their training. These hurdles result in data processing and documentation becoming a full time job, and indeed, it is becoming increasingly common for IEA teams to hire Data Analysts and Data Scientists to deal with the data deluge. 





# References
<div id="refs"></div>