---
title: Improving the IEA approach using principles of open data science
runtitle: Open data science in IEAs
#Finish list from google spreadsheet [https://docs.google.com/spreadsheets/d/1NO1_rLnXk3NYhwDPxaHtn6nEW_KFfgDYGK2qitXfSFI/edit#gid=0]
author: 
- name: Kimberly Bastille 
  institute: one
- name: Sean Hardison 
  institute: two
- name: Lynn DeWitt 
  institute: three
- name: Jennifer Brown 
  institute: four
- name: Jameal Samhouri 
  institute: five
- name: Sarah Gaichas 
  institute: six
- name: Sean Lucey 
  institute: six
- name: Kelly Kearney 
  institute: seven
- name: Ben Best 
  institute: eight
- name: Scott Cross 
  institute: nine
- name: Scott Large 
  institute: six
- name: Ellen Spooner 
  institute: ten
  
#Finish adding from the google spreadsheet [https://docs.google.com/spreadsheets/d/1NO1_rLnXk3NYhwDPxaHtn6nEW_KFfgDYGK2qitXfSFI/edit#gid: 
institute:
- one: Integrated Statistics, Woods Hole, MA, USA
- two: University of Virginia, Charlottesville, VA, USA
- three: Three
- four: Four 
- five: Five
- six: Woods Hole Laboratory, NOAA NMFS Northeast Fisheries Science Center, Woods Hole, MA, USA
- seven: University of Washington, Joint Institute for the Study of the Atmosphere and Ocean, Seattle, WA, USA
- eight: EcoQuants LLC, Santa Barbara, CA, USA
- nine: nine
- ten: ten
    
abstract: |
  The text of your abstract.  150 -- 250 words.
csl: estuaries-and-coasts.csl
bibliography: bibliography.bib
output:
  rmarkdown::pdf_document:
    pandoc_args: 
      - '--lua-filter=scholarly-metadata.lua'
      - '--lua-filter=author-info-blocks.lua'
    template: null
    extra_dependencies:
      - graphicx
      - array
      - booktabs
      - multirow
      - subfig
header-includes:
  - \usepackage[export]{adjustbox}
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
```

# Introduction {#intro}
<!-- Grab text from google doc, NOTE: this is sample text grabbed to set up bibliography -->

As implemented so far, integrated ecosystem assessments are more often than not bespoke products that are specific to regional policy needs at varying spatial scales. While unique, these assessments are typically built around the flow of the IEA framework outlined in [@Levin2009]. This process consists of a scoping step to outline management objectives, the identification of ecosystem indicators to monitor key processes, the compilation of ecosystem status reports highlighting status and trends of indicators, a risk assessment step identifying where ecosystem considerations might threaten management objectives, and finally management strategy evaluation, in which potential management actions are tested using simulation models. The elements of the IEA framework are central to its implementation, but its flow is not prescriptive. Instead, the IEA process is malleable to the needs of stakeholders, meaning that IEAs may manifest in many different forms. 

However, data acquisition, management, communication, and dissemination are universal challenges that apply across the disparate applications of IEAs. Solving these challenges is not trivial, but over the past decade several examples have emerged suggesting the use of open data science tools as potential solutions [@rocchini2012; @lowndes2015; @lowndes2017; @ma2018]. For example, Lowndes et al. 2017 discussed how embracing open science methods allowed for increased efficiency, transparency, and reproducibility in the development of the Ocean Health Index; a modular framework developed to assess the benefits of marine ecosystems to humans for sustainable management. Case studies for applying open science processes to IEAs have also been developed for ecosystem reporting in the Northeast Large Marine Ecosystem. Specifically, Ma et al. 2017 show how machine-readable provenance may be incorporated into automated analytical workflows using IPython and the Semantic Web. 

Embracing these tools and strategies speaks to a broader philosophy of open science that has yet to fully catch on in the IEA community. Beyond making data publicly available, open science advocates for the “free and unfettered access to all aspects of the scientific endeavor” [@hampton2015], including methods, data and scientific products. These values lend themselves to the broad applicability of IEAs as decision-making tools for ecosystem-based management (EBM). 

There are several entry and exit points for data, methodological, and scientific products throughout the execution of an IEA. Data entry points are formed during the exploratory phases of the IEA process, where objectives are scoped and representative indicators are developed. Exit points for data products can be found in the derived indicator data informing ecosystem status reports and risk assessments. Simulated products and model parameters, such as those resulting from MSE model runs, are also important to disseminate. Any data that leaves or enters an IEA brings with it metadata and code used to analyze, process, and visualize the data (in various stages of completion). Through the process these datasets, accompanying code, and metadata documentation become their own general, scientific and technical products feeding into subsequent products and adding transparency and efficiency (Fig. \@ref(fig:iealoop)). 

Without an underlying data management protocol, the vast quantities of data and documentation required to successfully execute an IEA can be overwhelming for practitioners and clients both. For example, the development of ecosystem status reports and risk assessments requires considering the management relevance of hundreds of data sets from many fields. In practice this meant sifting through over 400 unique spatial and temporal data sets that were submitted for consideration during the development of the New England State of the Ecosystem Report, an IEA product. However, only indicators of interest to managers and those necessary for storytelling were included in the final product; just over 90 [@SOE-NEFMC2019].  Depending on the governing body implementing the IEA, each data set must be fully documented with metadata and made publicly available. Versioning data sets and associated metadata relative to specific IEA products also introduces challenges for scientists operating outside the bounds of their training. These hurdles result in data processing and documentation becoming a full time job, and indeed, it is becoming increasingly common for IEA teams to hire Data Analysts and Data Scientists to deal with the data deluge. 

\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{./images/products-loop.pdf}
  \caption{Products as part of the IEA loop according to audience: general, scientific and technical.}
  \label{fig:products-loop}
\end{figure}

The implementation of IEA is an amalgam of the ecosystem and data sciences. Understanding this, we suggest that IEA teams embrace a philosophy of open science. This approach has gained momentum over the past decade within the ecological sciences as a way to deal with large amounts of data produced from a variety of sources [@michener2012], as well as to improve transparency, reproducibility, repeatability, and ease of communication of data products [@rocchini2012; @lowndes2015; @lowndes2017; @ma2018]. This can be accomplished using openly available tools, many of which are highlighted by @hampton2015 and @lowndes2017. 

The benefits of implementing software development strategies range from the ethical to the practical. For example, @lowndes2017 suggests that changing ecosystem conditions due to anthropogenic impacts necessitate openness among environmental scientists whose data (and code to recreate their data) provide “snapshots” of their study systems amidst the changes. Further, openly-sourcing scientific data with accompanying code provides a record from which previous results may be built upon as more data are collected [@lowndes2017]. From this perspective, iterative IEA products such as ecosystem reports and risk assessments are themselves data points; forming ever-extending arrays of compiled information through time. This approach has been embraced by the Ocean Health Index, which is designed to monitor human-ocean relationships through time by repeated compilation and analysis of ecosystem data [@halpern2012; @halpern2015; @lowndes2015]. 

We suggest that the incorporation of version control and standardized methods for the collection, aggregation, and dissemination of IEA-oriented data and products can facilitate flexible and efficient use of IEAs, broadening their applicability and hastening their uptake by resource managers. These methods also confront the challenging spatial aspects of IEAs, which are inherently unique to the systems being addressed. As we discuss below, embracing standardized methods and open data science principles/tools would facilitate the implementation of future IEAs in new systems.

<!---
### Scientific Workflow Panel: Figure & Table ###

Sources:
- figure: [ODM Fig work up.pptx - Google Slides](https://docs.google.com/presentation/d/1Cc4xI_xo_BVut_WJys-mFgxhDFfDxsSV/edit#slide=id.g6ba47551c5_1_0)
- table: [sciflow-tasks - Google Sheets](https://docs.google.com/spreadsheets/d/1J2psfQ-ZgwiS-9ak2g0wtXE9vj1FlzJaQufryIBqMgQ/edit#gid=0)

sciloop.pdf:
- Google Slides, File > Download > pdf -> sciloop.pdf
- Delete other pages; In AI, Release Clipping Mask twice, Fit to Artwork Bounds.

More on latex for side-by-side table and figure:
- [subfloats - Align figure and tables in subfigure environment - TeX - LaTeX Stack Exchange](https://tex.stackexchange.com/questions/455305/align-figure-and-tables-in-subfigure-environment)
-->

```{r workflow_table}
library(knitr)
library(tidyverse)
library(kableExtra)
library(here)

redo_workflow_tbl <- F
workflow_cols <- 1:2

workflow_csv  <- "https://docs.google.com/spreadsheets/d/1J2psfQ-ZgwiS-9ak2g0wtXE9vj1FlzJaQufryIBqMgQ/export?format=csv&gid=0"
#workflow_csv <- here("ODM/tables/workflow.csv")
workflow_tex <- here("ODM/tables/workflow.tex")

if (!file.exists(workflow_tex) | redo_workflow_tbl){

  tbl_workflow <- read_csv(workflow_csv) %>% 
    select(1:2) %>% 
    fill(1)

  kable(tbl_workflow, booktabs = T, format="latex") %>%
    #kable_styling(full_width = F, position = "right", font_size = 5) %>%
    kable_styling(font_size = 5) %>%
    column_spec(1, bold = T) %>%
    #column_spec(2, width = "20em") %>%
    collapse_rows(columns = 1, valign = "middle") %>% 
    str_replace(fixed("\\begin{table}[H]\n\\centering"), "") %>% 
    str_replace(fixed("\\end{table}"), "") %>% 
    cat(file = workflow_tex)
}
```

\begin{figure}
  \centering
  \subfloat[Process]{           
    \includegraphics[width=0.50\textwidth,valign=c]{./images/sciloop.pdf}
    \label{fig:sciflow-loop}
    }
  \subfloat[Elements]{
    \adjustbox{valign=c}{
      \input{./tables/workflow}
      \label{tbl:sciflow-table}}}
  \caption{Scientific workflow.}
\end{figure}

# References
<div id="refs"></div>